# 关于统计学习理论与支持向量机

[1]张学工.关于统计学习理论与支持向量机[J].自动化学报,2000(01):36-46.

机器学习的认识很多过时了，但统计学习理论的核心内容还是很重要

统计学习理论就是研究小样本统计估计和预测的理论 ,主要内容包括四个方面:
1) 经验风险最小化准则下统计学习一致性的条件;
2) 在这些条件下关于统计学习方法推广性的界的结论;
3) 在这些界的基础上建立的小样本归纳推理准则;
4) 实现新的准则的实际方法 (算法 ) .

VC维（函数集学习性能指标）

如果函数集能够把h个样本($$2^h$$种排列全部满足)分开，那么称函数集可以打散h个样本。函数的VC维就是它能打散的最大样本数。

n维实数空间内的线性分类器和线性实函数的VC维是$$n+1$$。

$$f(x,T)=sin(T*x)$$的VC维是无限大

> 如果VC维很小，那么发生预测偏差很大的坏事情的可能性也就很小，那这有利于Ein(g)接近Eout(g)；但是，这是我们的假设空间的表达能力受到了限制，这样Ein(g)可能就没有办法做到很小。

> 如果VC维很大，那么假设空间的表达能力很强，我们很有可能选到一个Ein(g)很小的假设，但是Ein(g)和Eout(g)之差很大的坏事情发生的情况发生的可能性就变得很大，这样Ein(g)和Eout(g)根本不接近，我们就无法确定选择的假设在测试数据的时候表现的很好。**（Ein(g)是训练集误差，Eout(g)是真实误差）**

经验风险 Remp ( w )和实际风险 R ( w )之间以至少 1- Z的概率满足如下关系 

![1557153220012](C:\Users\chunquan\AppData\Roaming\Typora\typora-user-images\1557153220012.png)

学习机器的实际风险是由两部分组成的: 一是经验风险 (训练误差 ) ,另一部分称作置信范围 ,它和学习机器的 V C维及训练样本数有关

![1557153292057](C:\Users\chunquan\AppData\Roaming\Typora\typora-user-images\1557153292057.png)

> 把函数集构造为一个函数子集序列 ,使各个子集按照V C维的大小 (亦即 H的大小 )排列;在每个子集中寻找最小经验风险 ,在子集间折衷考虑经验风险和置信范围 ,取得实际风险的最小 ,如图 1所示.这种思想称作结构风险最小化 ( Structural Risk Minimization或译有序风险最小化，即 SRM 准则

![1557153501074](C:\Users\chunquan\AppData\Roaming\Typora\typora-user-images\1557153501074.png)

> 实现 SRM 原则可以有两种思路 ,一是在每个子集中求最小经验风险 ,然后选择使最小经验风险和置信范围之和最小的子集.显然这种方法比较费时 ,当子集数目很大甚至是无穷时不可行 .因此有第二种思路 ,即设计函数集的某种结构使每个子集中都能取得最小的经验风险 (如使训练误差为 0) ,然后只需选择选择适当的子集使置信范围最小 ,则这个子集中使经验风险最小的函数就是最优函数 .支持向量机方法实际上就是这种思想的具体实现。

核方法

核函数主成分分析